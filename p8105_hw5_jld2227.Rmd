---
title: "Homework 5"
author: "James Dalgleish"
date: "November 2, 2018"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
```

### Problem 1

To begin, we'll download the file, extract it's contents, and clean up the unnecessary files. 
```{r data_dl}
#Download and extract source data from zip archive.
download.file(url = "http://p8105.com/data/hw5_data.zip", 
              destfile =  "hw5_data.zip")
unzip(zipfile = "hw5_data.zip", exdir = "data", junkpaths = T) #extract the files into this new directory
study_csvs <- list.files(path = "data",pattern = "^.[A-z]*.*\\.csv$", full.names = T) #grab just the real CSVs beginning with a letter and ending with a .csv, avoiding unimportant files in the archive.

#delete the extra csvs and ._data in the __MACOSX folder of the archive.
#a setdiff will include the . and .., which we can't remove, so specific commands are needed.
if ( Sys.info()['sysname'] == "Windows") {
extra_files <- list.files('data',all.files = T, "^[.].*\\.csv$", full.names = T)
#grabs the files that are csv, but begin with a period (not the real datafiles).
file.remove(extra_files) #deletes these extra csvs.
file.remove("./data/._data") #deletes this extra ._data file.
file.remove("hw5_data.zip") #deletes the zip file
}
```
Now that we have the raw data, we'll import it and convert the contents of the individual subject data into a comprehensive table in long format that is amenable to data analysis, incorporating information about the subject contained in the filename.
```{r data_import}
read_w_fn <- function(csv, basename = T) { #the basename argument ensures the function is more generalizable to future problems where the full file path is desired in the output (in which case the user can set this flag to false).
  #browser()
  if (basename) {
    
  df <- read_csv(csv) %>% #read in csv file.
    mutate(source_file = #add a column for filename from whence the rows came.
             basename(csv) #putting in a single value still allows for recycling.
           #So, this procedure will always work in this function.
              #https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html
                 )
  } else {
    df <- read_csv(csv) %>% 
    mutate(source_file = csv) #this option just takes the filename as is, without removing directory structure.
  }
}
#test reading a file with the function:
#read_w_fn(study_csvs[1])

study_data <- study_csvs   %>%  #Creates a dataframe from the columns.
   map_df(.f = read_w_fn) %>% #reads in all the csvs and puts them together into a single dataframe by binding the rows together. 
  gather(key = "week", value = "measurement", starts_with("week")) %>%  #converts weeks to long format.
  mutate(week = (str_replace(week,"week_","") %>% 
           as.numeric()), #creates a numeric week variable
         arm = str_replace(basename(source_file),"_.*$",""), #creates a categorical arm variable by removing the text after con or exp.
         subject_id = (str_extract( #extracts the subject number from the filename.
           basename(source_file), #removes the directory information from the filename.
           "(\\d)+") %>% #specifies the numbers within the filename as the string to be extracted.
                         as.numeric()) #converts subject ID to numeric
         ) 

```

Instructions: Tidy the result; manipulate file names to include control arm and subject ID, make sure weekly observations are “tidy”, and do any other tidying that’s necessary
Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups.
```{r spaghetti_plot}
spaghetti_con_exp <- 
```

### Problem 2